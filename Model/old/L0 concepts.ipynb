{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Import classes\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from conpact2 import *\n",
      "from nips import *\n",
      "import itertools"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "*Testing version*"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Set up domain:\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "features = 2\n",
      "concepts = 3**features\n",
      "objects = 2**features\n",
      "words = 2\n",
      "utts = np.array([[1,0],[0,1]])\n",
      "max_utterance_length = 1\n",
      "num_utts = len(utts)\n",
      "lexicon = np.array([0,2])\n",
      "log_object_prior = np.ones(objects)\n",
      "\n",
      "conceptsA = np.array(list(itertools.product([0, 1, 2], repeat=features)))\n",
      "objectsA = np.array(list(itertools.product([1, 2], repeat=features)))\n",
      "lexicons = np.array(list(itertools.product(range(concepts), repeat=words))) #generate all lexicons\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "words"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "2"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "concepts"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "9"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "objects"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "4"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Utterances, U1 = word1, U2 = word2 (two single word utterances)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "utts"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 29,
       "text": [
        "array([[1, 0],\n",
        "       [0, 1]])"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Lexicon, where word 1 linked to concept [1 1] and word 2 linked to concept [2 2]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lexicon"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 28,
       "text": [
        "array([[0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
        "       [0, 0, 0, 0, 0, 0, 0, 0, 1]])"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Objects"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "objectsA"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "array([[1, 1],\n",
        "       [1, 2],\n",
        "       [2, 1],\n",
        "       [2, 2]])"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Concepts"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "conceptsA"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "array([[0, 0],\n",
        "       [0, 1],\n",
        "       [0, 2],\n",
        "       [1, 0],\n",
        "       [1, 1],\n",
        "       [1, 2],\n",
        "       [2, 0],\n",
        "       [2, 1],\n",
        "       [2, 2]])"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Set up o_by_c\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "o_by_c = np.zeros(shape=(objects,concepts))\n",
      "\n",
      "for o in range(0,objects):\n",
      "    current_o = objectsA[o,:]\n",
      "    for c in range(0,concepts):\n",
      "        current_c= conceptsA[c,:]\n",
      "        concept_check = np.zeros(features)\n",
      "        for f in range(0,features):\n",
      "            if ((current_c[f] == current_o[f]) or (current_c[f] == 0)):\n",
      "                concept_check[f] = 1\n",
      "            else:\n",
      "                concept_check[f] = 0\n",
      "        if all(concept_check):\n",
      "            o_by_c[o,c] = 1\n",
      "            \n",
      "o_by_c"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "array([[ 1.,  1.,  0.,  1.,  1.,  0.,  0.,  0.,  0.],\n",
        "       [ 1.,  0.,  1.,  1.,  0.,  1.,  0.,  0.,  0.],\n",
        "       [ 1.,  1.,  0.,  0.,  0.,  0.,  1.,  1.,  0.],\n",
        "       [ 1.,  0.,  1.,  0.,  0.,  0.,  1.,  0.,  1.]])"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Go from w x c -> u x o (via o_by_c)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "P_L = np.zeros(shape=(num_utts,objects))\n",
      "\n",
      "for u in range(0,num_utts): # loop over utterances\n",
      "    current_utt = utts[u]\n",
      "    for o in range(0,objects): #loop over object\n",
      "        true_words_in_utt = np.zeros(words)\n",
      "        for w in range(0,words): #loop over each word in utterance\n",
      "            if (current_utt[w] != 0):\n",
      "                true_obj = 0\n",
      "                for c in range(0,concepts): #loop over each concept in lexicon\n",
      "                    # if word is linked to concept and concept linked to object\n",
      "                    if ((lexicon[w,c] == 1) and (o_by_c[o,c] == 1)): \n",
      "                        true_obj = 1\n",
      "                true_words_in_utt[w] = true_obj      \n",
      "                #P_L[u,o] = np.prod(true_words_in_utt[true_words_in_utt>0]) \n",
      "                P_L[u,o] = (np.sum(true_words_in_utt)) > 0 # if object true of any word in uttrance\n",
      "\n",
      "\n",
      "#logP_L = np.log(P_L)\n",
      "P_L\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 27,
       "text": [
        "array([[ 1.,  0.,  0.,  0.],\n",
        "       [ 0.,  0.,  0.,  1.]])"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "New version using Nathaniel's code. \n",
      "\n",
      "Nathaniel's code goes from wXo -> uXo\n",
      "\n",
      "What we want to do is go from wXc -> wXo (via oXc) -> uXo\n",
      "\n",
      "So, we ant to create a wXo thing and then pass it to Nathaniels code. \n",
      "\n",
      "The other change is to think abotu the lexicon in the new was 1X|w|.\n",
      "\n",
      "So, it's ACTUALLY: 1X|w| -> wXo (via oXc) -> uXo"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wXo = np.zeros(shape=(words,objects))\n",
      "\n",
      "for w in range(0, words):\n",
      "    wXo[w,:] = o_by_c[:,lexicon[w]] \n",
      "    \n",
      "# The indexing needs to be fixed if we want words to be able to be linked to no concept\n",
      "# There's no way in the current representation to indicate a null link (because 0 indexes a concept)\n",
      "# need to generage lexicons with range(concepts + 1)\n",
      "    \n",
      "wXo"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "array([[ 1.,  1.,  1.,  1.],\n",
        "       [ 0.,  1.,  0.,  1.]])"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, Add this to L0:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "        log_object_prior = self.log_object_prior(log_object_prior)\n",
      "        wXo = np.zeros(shape=(words,objects))\n",
      "\n",
      "        # generate wXo via o_by_c (equivalent to the \"lexicon\" in the old model)\n",
      "        for w in range(0, words):\n",
      "            wXo[w,:] = o_by_c[:,lexicon[w]] \n",
      "            \n",
      "        log_lexicon = np.log(wXo) # the \"lexicon\" here is wXo\n",
      "        \n",
      "        # literal P(obj|utt) is, by stipulation, proportional to the product\n",
      "        # of P(obj|word) for all words in utt. Then we multiply by the\n",
      "        # (context specific) object prior.\n",
      "        logP_L = np.dot(self.utts, log_lexicon)\n",
      "        logP_L += log_object_prior[np.newaxis, :]\n",
      "        logZ = np.logaddexp.reduce(logP_L, axis=1)\n",
      "        logP_L -= logZ[:, np.newaxis]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "__Things to think about__: \n",
      "\n",
      "(1) If any word in utterance is linked to object, u(o) = T. But we might want this to be graded? resolved by just using existing code.\n",
      "\n",
      "(2) Impose constraints on lexicons (1-1)? Yes.\n",
      "\n",
      "(3) If object is true of concept, then o_c = T. But we might want this to be graded (as function of number of shared features)? maybe later...\n",
      "\n",
      "SIMS:\n",
      "run ME\n",
      "run bandana"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "TO DO"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "(1) Get this to do inference. Figure out how to enumerate lexicons.\n",
      "\n",
      "(2) What are the interesting experimental conditions to run? \n",
      "\n",
      "__Idea 1__: 'w1 [1 1]' and then test on either (a) 'w2 [1 1] [2 2]', or (b) 'w2 [1 1] [1 2]' =>   expect graded generalization?\n",
      "\n",
      "__Idea 2__: \n",
      "\n",
      "1) Since we predict a difference between on-the-fly pragmatic\n",
      "interpretations and the resulting beliefs about literal meaning, probe\n",
      "each separately. To assess pragmatic interpretation, do an ME-style\n",
      "experiment (\"the alien said to click on the 'fep', which one do you\n",
      "think they wanted you to click on?\"); then to assess literal meaning,\n",
      "do a post-test without any communicative context (\"which of these\n",
      "objects do you think the word 'fep' could refer to?\").\n",
      "\n",
      "2) To create interesting differences and the possibility of\n",
      "generalization, use stimuli with features that allow for interesting\n",
      "subordinate/superordinate categories and specificity implicatures. So\n",
      "the core example we were thinking of is a contrast between two\n",
      "objects:\n",
      "  Object 1: one familiar/nameable feature, one novel feature\n",
      "  Object 2: one novel feature *shared with object 1*, one unique novel feature\n",
      "So the familiar feature on object 1 suggests that by ME, a novel word\n",
      "should refer to object 2. But in a learning+pragmatics+concepts model,\n",
      "this might be because \"fep\" literally refers to the *shared* feature\n",
      "and is being pragmatically strengthened; without pragmatics, it needs\n",
      "to refer to the unique feature, or perhaps a conjunction.\n",
      "\n",
      "'w1 1[N1, F1] 2[N1 N2]' w1 -> 2 ... but could refer to N1 (pragmaticall strengthened) or N2 (without pragmatics, a constraint)\n",
      "\n",
      "*this is really similiar to what Elise is doing, except without ME\n",
      "    \n",
      "    "
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "*Actual version*"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lexicon_prior = [[5, 1, 1, 1, 1, 1, 1, 1 ,1], [1, 1, 1, 1, 1, 1, 1, 1 ,1]]\n",
      "listener = conpact2.FixedSupportImportanceSampler(d, 0, PARTICLES * 10,\n",
      "                                                  lexicon_prior=lexicon_prior)\n",
      "listener.add_data([conpact2.LDataUtt(LISTENER_DEPTH - 1, 1)])\n",
      "def show_ME_posterior(path, listener):\n",
      "    show_lex_posterior(path, listener.weighted_lexicons(), (0, 0), (1, 0),\n",
      "                       xlabel=\"P(Familiar word literally means familiar object)\",\n",
      "                       ylabel=\"P(Novel word literally means familiar object)\")\n",
      "show_ME_posterior(\"ME-prior.pdf\", listener)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.array(list(itertools.product(range(concepts), repeat=words))) #generate all lexicons"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 28,
       "text": [
        "array([[0, 0],\n",
        "       [0, 1],\n",
        "       [0, 2],\n",
        "       [0, 3],\n",
        "       [0, 4],\n",
        "       [0, 5],\n",
        "       [0, 6],\n",
        "       [0, 7],\n",
        "       [0, 8],\n",
        "       [0, 9],\n",
        "       [1, 0],\n",
        "       [1, 1],\n",
        "       [1, 2],\n",
        "       [1, 3],\n",
        "       [1, 4],\n",
        "       [1, 5],\n",
        "       [1, 6],\n",
        "       [1, 7],\n",
        "       [1, 8],\n",
        "       [1, 9],\n",
        "       [2, 0],\n",
        "       [2, 1],\n",
        "       [2, 2],\n",
        "       [2, 3],\n",
        "       [2, 4],\n",
        "       [2, 5],\n",
        "       [2, 6],\n",
        "       [2, 7],\n",
        "       [2, 8],\n",
        "       [2, 9],\n",
        "       [3, 0],\n",
        "       [3, 1],\n",
        "       [3, 2],\n",
        "       [3, 3],\n",
        "       [3, 4],\n",
        "       [3, 5],\n",
        "       [3, 6],\n",
        "       [3, 7],\n",
        "       [3, 8],\n",
        "       [3, 9],\n",
        "       [4, 0],\n",
        "       [4, 1],\n",
        "       [4, 2],\n",
        "       [4, 3],\n",
        "       [4, 4],\n",
        "       [4, 5],\n",
        "       [4, 6],\n",
        "       [4, 7],\n",
        "       [4, 8],\n",
        "       [4, 9],\n",
        "       [5, 0],\n",
        "       [5, 1],\n",
        "       [5, 2],\n",
        "       [5, 3],\n",
        "       [5, 4],\n",
        "       [5, 5],\n",
        "       [5, 6],\n",
        "       [5, 7],\n",
        "       [5, 8],\n",
        "       [5, 9],\n",
        "       [6, 0],\n",
        "       [6, 1],\n",
        "       [6, 2],\n",
        "       [6, 3],\n",
        "       [6, 4],\n",
        "       [6, 5],\n",
        "       [6, 6],\n",
        "       [6, 7],\n",
        "       [6, 8],\n",
        "       [6, 9],\n",
        "       [7, 0],\n",
        "       [7, 1],\n",
        "       [7, 2],\n",
        "       [7, 3],\n",
        "       [7, 4],\n",
        "       [7, 5],\n",
        "       [7, 6],\n",
        "       [7, 7],\n",
        "       [7, 8],\n",
        "       [7, 9],\n",
        "       [8, 0],\n",
        "       [8, 1],\n",
        "       [8, 2],\n",
        "       [8, 3],\n",
        "       [8, 4],\n",
        "       [8, 5],\n",
        "       [8, 6],\n",
        "       [8, 7],\n",
        "       [8, 8],\n",
        "       [8, 9],\n",
        "       [9, 0],\n",
        "       [9, 1],\n",
        "       [9, 2],\n",
        "       [9, 3],\n",
        "       [9, 4],\n",
        "       [9, 5],\n",
        "       [9, 6],\n",
        "       [9, 7],\n",
        "       [9, 8],\n",
        "       [9, 9]])"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "        log_object_prior = self.log_object_prior(log_object_prior)        \n",
      "        o_by_w = np.dot(self.o_by_c,np.transpose(lexicon))\n",
      "        P_L = np.dot(o_by_w, np.transpose(self.utts))\n",
      "        \n",
      "        logP_L = np.log(np.transpose(P_L)) #put P(utt|obj) in log space\n",
      "        logZ = np.logaddexp.reduce(logP_L, axis=1) # get sum (denominator for normalization)\n",
      "        logP_L -= logZ[:, np.newaxis] # normalize"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "0"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "w_by_o = np.zeros(shape=(words,objects))\n",
      "\n",
      "# generate wXo via o_by_c (equivalent to the \"lexicon\" in the old model)\n",
      "for w in range(0, words):\n",
      "        w_by_o[w,:] = o_by_c[:,lexicon[w]] \n",
      "\n",
      "# add noise\n",
      "noise = .1\n",
      "\n",
      "w_by_o_noise = np.ones(shape=np.shape(w_by_o))\n",
      "w_by_o_noise_Z = np.add.reduce(w_by_o_noise, axis=1) # normalize noise\n",
      "w_by_o_noise /= w_by_o_noise_Z [:, np.newaxis]\n",
      "\n",
      "w_by_o_Z = np.add.reduce(w_by_o, axis=1) # normalize w_by_o\n",
      "w_by_o /= w_by_o_Z[:, np.newaxis]\n",
      "\n",
      "w_by_o_noise *=  noise \n",
      "w_by_o *= 1-noise\n",
      "w_by_o += w_by_o_noise \n",
      "\n",
      "w_by_o\n",
      "\n",
      "#log_wXo= np.log(w_by_o) # put in log space\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 56,
       "text": [
        "array([[ 0.25 ,  0.25 ,  0.25 ,  0.25 ],\n",
        "       [ 0.025,  0.475,  0.025,  0.475]])"
       ]
      }
     ],
     "prompt_number": 56
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "thing = np.ones((words,concepts))\n",
      "np.asarray(thing)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 62,
       "text": [
        "array([[ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n",
        "       [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]])"
       ]
      }
     ],
     "prompt_number": 62
    }
   ],
   "metadata": {}
  }
 ]
}